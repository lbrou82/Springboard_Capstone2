{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center> Image Classification of Birds using the iNaturalist Dataset</center></h2>\n",
    "<h3><center>Springboard | Capstone 2: In-Depth Analysis/Modeling </center></h3>\n",
    "<h4><center>By: Lauren Broussard</center></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split # to split into training and testing data \n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator # for image processing\n",
    "from keras.models import Sequential,load_model #used to build initial model \n",
    "from keras.layers import Activation, Dense, Dropout, Flatten #Dense used to add layers to model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.optimizers import SGD #this is for optimization on learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run our project from end to end with this number of images to account for run time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_COUNT = int(input(\"Total Images To Use: \")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the computing power on my personal laptop is limited, I will run the project end to end with a smaller amount of images, and will gradually increase the number of images over time. \n",
    "\n",
    "To this end, we'll import our original file, and grab a random subset of images to train, validate, and test with. Further, to balance out our dataset, we'll take an equal number of images showing birds and an equal number that are not birds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clean annotation file\n",
    "df = pd.read_csv('../data/interim/wildlife_interim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random sample of images -- half birds, and half not birds\n",
    "df_bird = df[df.is_bird == 1].sample(n=int(IMG_COUNT/2), random_state=42) # half birds\n",
    "df_no_bird = df[df.is_bird == 0].sample(n=int(IMG_COUNT/2),random_state=42) # half not birds\n",
    "df = pd.concat([df_bird, df_no_bird], axis=0) #merge two groups together\n",
    "df.is_bird = df.is_bird.astype(str) # change bird indicator to string to fit model specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into training, validation, and test dataframes\n",
    "df_train, df_val = train_test_split(df,test_size=0.2, random_state=42)\n",
    "df_train, df_test = train_test_split(df_train,test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Number of Training Images: \",len(df_train))\n",
    "print(\"Number of Validation Images: \", len(df_val))\n",
    "print(\"Number of Test Images: \", len(df_test),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET UP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set some constant values for our model below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "img_dir = \"../data/raw/\" # where images are stored\n",
    "img_width, img_height = 128,128 # resize images to account for smallest img size\n",
    "batch_size = 128\n",
    "no_epochs = 50\n",
    "no_classes = 2 # choices of bird or not bird\n",
    "patience = 7 # for Early Stopping callback \n",
    "\n",
    "print('img_dir = ', img_dir)\n",
    "print('img_width, img_height = ',img_width, img_height)\n",
    "print('batch_size = ', batch_size)\n",
    "print('no_epochs = ', no_epochs)\n",
    "print('no_classes = ', no_classes)\n",
    "print('patience = ', patience, '\\n')\n",
    "\n",
    "#how many epochs to go without model improving \n",
    "early_stopping_monitor = EarlyStopping(patience=patience) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment Images - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do random augmentation of our each of our image subgroups, which will help rescale and shift them, and can help prevent overfitting for our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\")\n",
    "print(\"Augment Images - Training\")\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255, \n",
    "                    horizontal_flip = True,    \n",
    "                    zoom_range = 0.3,\n",
    "                    width_shift_range = 0.15,\n",
    "                    height_shift_range=0.15)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                    dataframe= df_train,\n",
    "                    directory=img_dir,\n",
    "                    x_col=\"file_name\",\n",
    "                    y_col=\"is_bird\",\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    class_mode=\"binary\",    \n",
    "                    target_size=(img_height,img_width))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment Images - Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\")\n",
    "print(\"Augment Images - Validation and Testing\")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator=val_datagen.flow_from_dataframe(\n",
    "                    dataframe=df_val,\n",
    "                    directory=img_dir,\n",
    "                    x_col=\"file_name\",\n",
    "                    y_col=\"is_bird\",\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode=\"binary\",    \n",
    "                    target_size=(img_height,img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions for Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_and_loss(model):\n",
    "    '''Create graphs of training and validation accuracy and loss.'''\n",
    "    \n",
    "    acc = model.history['accuracy']\n",
    "    val_acc = model.history['val_accuracy']\n",
    "\n",
    "    loss = model.history['loss']\n",
    "    val_loss = model.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
